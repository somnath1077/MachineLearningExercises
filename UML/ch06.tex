\chapter{The VC-Dimension}

\section*{Notes on Chapter 6}

We know that finite hypothesis classes are agnostic PAC learnable (and hence
PAC learnable).  What about infinite hypothesis classes? The first example is 
that of an infinite hypothesis class that is PAC learnable. 

\begin{example}[Threshold Functions]
Let $\dom = [0, 1]$ and $\range = \{0, 1\}$. For $r \in [0, 1]$, define 
$h_r \colon \dom \rightarrow \range $ as:
\[
    h_r(x) = \left \{ \begin{array}{ll} 
                        0 & \text{if } x \leq r \\
                        1 & \text{if } x > r
                      \end{array}\right .
\]
Let $\hypclass_{\text{thr}}$ be the set of all threshold functions $h_r$ 
for $r \in [0, 1]$. Since $\hypclass_{\text{thr}}$ is not finite, it is 
not immediately obvious whether it is PAC learnable (in the realizable case). 

Fix $\epsilon, \delta \in (0, 1)$. Let $f = h_s$ be the true labeling function
where $s \in [0, 1]$ and let $\dist$ be the underlying distribution over the
domain $[0, 1]$. Let $s_0 \in [0, s)$ and $s_1 \in [s, 1]$ be numbers such that  
\[
    \dist \left \{ x \in [s_0, s) \right \} = \epsilon =  
    \dist \left \{ x \in [s, s_1] \right \}
\]
If $\dist \left \{ [0, s) \right \} < \epsilon$, then set $s_0 = 0$; similarly, 
if $\dist \left \{ [s, 1] \right \} < \epsilon$, set $s_1 = 1$. Since $\dist$ 
is a distribution, it must place a probability mass of $\epsilon$ either to 
the left or to the right of $s$. 

Given a sample $S$, let $t_0 = \max \{t \colon (t, 0) \in S\}$ and $t_1 = \min
\{t \colon (t, 1) \in S\}$. The ERM algorithm outputs $h_p$, where $p \in (t_0,
t_1)$.  In particular, if the sample presented to the ERM algorithm is such
that $s_0 \leq t_0$ and $t_1 \leq s_1$, then hypothesis $h_p$ returned by the ERM
algorithm will incur a loss of $L_{\dist}(h_p) \leq \epsilon$.

Thus the probability that the hypothesis $\ERM(S)$ output by the ERM algorithm 
has a loss greater than $\epsilon$ on a sample $S$ of size $m$ is:
\begin{align*}
    \Prtwo{S \sim \dist^m}{L_{\dist} (\ERM(S)) > \epsilon} 
     & = \Prtwo{S \sim \dist^m}{S \colon t_0 < s_0 \vee s_1 < t_1} \\
     & \leq  \Prtwo{S \sim \dist^m}{S \colon S|_x \cap [s_0, s) = \emptyset} + 
             \Prtwo{S \sim \dist^m}{S \colon S|_x \cap [s, s_1] = \emptyset} \\      
     & \leq 2 \cdot (1 - \epsilon)^m \\
     & \leq 2 \cdot e^{- \epsilon m}
\end{align*}
Setting the last expression to be at most $\delta$, we obtain that 
$m > \frac{1}{\epsilon} \cdot \log \frac{2}{\delta}$. Hence if we have samples 
of size at least $\frac{1}{\epsilon} \cdot \log \frac{2}{\delta}$, 
\[
    \Prtwo{S \sim \dist^m}{L_{\dist} (\ERM(S)) \leq \epsilon} \geq 1 - \delta, 
\]
which is the condition for PAC learnability.
\end{example}

The second example shows that there are infinite hypothesis classes that are not
PAC learnable at least by using an ERM strategy.

\begin{example}[Identity Function for Finite Sets] 
Let $\dom = \Rone$ and $\range = \{0, 1\}$. Given a set $A \subseteq \dom$,
define $h_A$ as follows:
\[
    h_A = \left \{ \begin{array}{ll} 
                        1 & \text{if } x \in A \\
                        0 & \text{otherwise}
                   \end{array}\right .
\]
Let $\hypclass_{\text{finite}}$ be the set of all such functions $h_A$ for \emph{finite} 
subsets $A$ of $\Rone$ along with the function $h_{1}$ which maps every point in $\Rone$ 
to $1$. We claim that $\hypclass_{\text{finite}}$ is not PAC learnable by an ERM algorithm. 

Consider the case when the true labeling function $f = h_1$, the all-ones
function on $\Rone$ and $\dist$ is the uniform distribution on $[0, 1]$. Since
$f \in \hypclass_{\text{finite}}$, we are assuming that the hypothesis class is
realizable. Fix any sample size $m$. A sample $S$ in this case looks like
$\{(x_1, 1), \ldots, (x_m, 1)\}$ and an obvious ERM strategy is to output $h_A$
for $A = \{x_1, \ldots, x_m\}$. Clearly $L_S (h_A) = 0$ but $L_{\dist} (h_A) =
1$.  
\end{example} 

The previous examples show that the size of the hypothesis class does not characterize
whether it is learnable. This characterization is provided by the so-called VC-dimension.

\section*{Exercise 6.1}

Let $\hypclass$ be a set of functions from $\dom$ to $\{0, 1\}$ and
let $\hypclass' \subseteq \hypclass$. Assume that $\vcdim (\hypclass') > \vcdim
(\hypclass)$.  Then there exists a set $C \subseteq \dom$ that is shattered by
$\hypclass'$ but not by $\hypclass$.  This implies that for all $g \colon C
\rightarrow \{0, 1\}$ there exists $h' \in \hypclass'$ such that $g(x) = h'(x)$
for all $x \in C$. Since $h' \in \hypclass$, this implies that $\hypclass$
shatters $C$, a contradiction.

\section*{Exercise 6.2}

In this exercise, $\dom$ is finite and $k \leq |\dom| =: n$. 

\subsection*{6.2.1} 

We claim that 
\[\vcdim(\hypclass_{= k}) 
= \left \{ \begin{array}{ll} 
                k     & \text{if } k \leq \floor{n / 2} \\
                n - k & \text{if } k > \floor{n / 2} 
           \end{array} \right .
\]

Suppose that $k \leq \floor{n / 2}$ and consider a subset $C \subset \dom$ 
of size $k + 1$. Then the all-one function on $C$ cannot be 
extended to a function in $\hypclass_{= k}$ as it maps $k + 1$ elements
of $\dom$ to $1$. Hence $\vcdim(\hypclass_{= k}) \leq k$. If $|C| = k$ 
and $g \colon C \rightarrow \{0, 1\}$ that maps $k'$ elements of $C$ to $1$,
we can extend $g$ to a function on $\dom$ that maps exactly $k$ elements of 
$\dom$ to $1$.  This shows that $\vcdim(\hypclass_{= k}) \geq k$. Hence 
$\vcdim{\hypclass_{= k}} = k$.

Now consider the case $k > \floor{n / 2}$. If $C$ is subset of size
$n - k + 1$, then the all-zero function on $C$ cannot be extended 
to a function in $\hypclass_{= k}$. This happens because there are only 
$n - (n - k + 1) < k$ elements in $\dom \setminus C$. Hence 
$\vcdim(\hypclass_{= k}) \leq n - k$. If $|C| = n - k$ and 
$g \colon C \rightarrow \{0, 1\}$ that assigns $1$ to $k'$ 
elements of $C$, then we can extend $g$ to a function in 
$\hypclass_{= k}$ as we have at least $k - k'$ elements in 
$\dom \setminus C$ which we can map to $1$. This shows that 
$\vcdim(\hypclass_{= k}) \geq n - k$. Hence 
$\vcdim(\hypclass_{= k}) = n - k$.

\subsection*{6.2.2}

First observe that if $k \geq \floor{n / 2}$, then $\hypclass_{\leq k}$ includes 
all possible functions from $\dom$ to $\{0, 1\}$. This is because any function 
$g \colon \dom \rightarrow \{0, 1\}$ maps at most half the elements of 
$\dom$ to either $0$ or $1$ and hence is in $\hypclass_{\leq k}$. 
Hence in this case every subset of $\dom$ is shattered by $\hypclass_{\leq k}$
and $\vcdim (\hypclass_{\leq k}) = n$.

If $k < \floor{n / 2}$, then we claim that  $\vcdim (\hypclass_{\leq k}) = 2k + 1$.
Let $C \subset \dom$ of size $2k + 1$ and consider a function 
$g \colon C \rightarrow \{0, 1\}$. Such a function maps at most $k$ elements 
to either $0$ or $1$. Suppose that it maps at most $k$ elements to $1$. Extend
$g$ to a function on $\dom$ by mapping all elements of $\dom \setminus C$ to $0$. 
This extension is a function on $\dom$ that maps at most $k$ elements to $1$
and hence is an element of $\hypclass_{\leq k}$. The reasoning is similar had $g$ 
mapped at most $k$ elements to $0$. This show that 
$\vcdim(\hypclass_{\leq k}) \geq 2k + 1$. 

Now suppose that $C \subset \dom$ is of size $2k + 2$. Consider a map  
that assigns half the elements of $C$ to $0$ and the other half to $1$. 
This map cannot be extended to a function in $\hypclass_{\leq k}$. This 
proves that $\vcdim (\hypclass_{\leq k}) \leq 2k + 1$. Thus:
\[\vcdim(\hypclass_{\leq k}) 
= \left \{ \begin{array}{ll} 
                2k + 1  & \text{if } k < \floor{n / 2} \\
                n       & \text{if } k \geq \floor{n / 2} 
           \end{array} \right .
\]


  
