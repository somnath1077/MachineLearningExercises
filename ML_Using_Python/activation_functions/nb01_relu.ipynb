{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551eacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335aa51",
   "metadata": {},
   "source": [
    "## Create Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f24f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n=100):\n",
    "    \"\"\"\n",
    "        f(x1, x2) = 5 * x_1**2 + 4 * x_2**2 - 3 * x_1 * x_2\n",
    "    \"\"\"\n",
    "    ret = np.zeros(shape=(n, 3)).astype(\"float32\")\n",
    "    x = np.random.rand(n, 2)\n",
    "    y = (5 * x[:, 0]**2 + 4 * x[:, 1]**2 - 3 * x[:, 0] * x[:, 1]).reshape(-1, 1)\n",
    "    ret[:, [0, 1]] = x\n",
    "    ret[:, [2]] = y\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a061d",
   "metadata": {},
   "source": [
    "## Test Out Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b073b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = create_data(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1e07e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37237087, 0.23720594, 0.65338117],\n",
       "       [0.53994864, 0.86439043, 3.0462265 ],\n",
       "       [0.49579495, 0.5879997 , 1.7374558 ],\n",
       "       [0.39533043, 0.8266355 , 2.534353  ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bef7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6534, 0.6534)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = round(5 * d[0, 0]**2 + 4 * d[0, 1]**2 - 3 * d[0, 0] * d[0, 1], 4)\n",
    "exp_val = round(d[0, 2], 4)\n",
    "\n",
    "val, exp_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e8b2e",
   "metadata": {},
   "source": [
    "## Create Network\n",
    "\n",
    "The network that we will create will have two dense layers with ReLU activations. The goal is to see how many of these neurons become \"dead\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241876a",
   "metadata": {},
   "source": [
    "### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8a8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 1000\n",
    "TRAIN_FRAC = 0.60\n",
    "VAL_FRAC = 0.20\n",
    "\n",
    "data = create_data(n=1000)\n",
    "\n",
    "train_idx = int(TRAIN_FRAC * NUM_SAMPLES)\n",
    "val_idx = train_idx + int(VAL_FRAC * NUM_SAMPLES)\n",
    "\n",
    "train_data = data[: train_idx]\n",
    "val_data = data[train_idx: val_idx]\n",
    "test_data = data[val_idx: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91678b05",
   "metadata": {},
   "source": [
    "### Normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579e11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data: np.array, mean: np.array=None, sd: np.array=None):\n",
    "    if (mean is not None) and (sd is not None):\n",
    "        assert data.shape[1] == len(mean) == len(sd)\n",
    "    \n",
    "    if mean is None:\n",
    "        mean = data.mean(axis=0)\n",
    "    if sd is None:\n",
    "        sd = data.std(axis=0)\n",
    "    \n",
    "    normed = (data - mean) / sd\n",
    "    \n",
    "    return mean, sd, normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9713d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, sd, norm_train_data = normalize(train_data)\n",
    "_, _, norm_val_data = normalize(val_data, mean=mean, sd=sd)\n",
    "_, _, norm_test_data = normalize(test_data, mean=mean, sd=sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437286d",
   "metadata": {},
   "source": [
    "### Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553b3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=2)\n",
    "dense_1 = layers.Dense(units=10, activation='relu')(inputs)\n",
    "dense_2 = layers.Dense(units=10, activation='relu')(dense_1)\n",
    "output = layers.Dense(units=1, activation=None)(dense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2a92b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2b5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f50af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98c6a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 43ms/step - loss: 7.4809 - val_loss: 7.6195\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 6.8471 - val_loss: 7.1371\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 6.4327 - val_loss: 6.7309\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 6.0743 - val_loss: 6.3624\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.7431 - val_loss: 6.0159\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.4265 - val_loss: 5.6851\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 5.1218 - val_loss: 5.3609\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.8255 - val_loss: 5.0454\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.5401 - val_loss: 4.7368\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.2651 - val_loss: 4.4391\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((test_data[:, [0, 1]], \n",
    "                                                    test_data[:, [2]])).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data[:, [0, 1]], \n",
    "                                                  val_data[:, [2]])).batch(BATCH_SIZE)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_dataset, \n",
    "                    callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36d40d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data[:, [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f7a1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3786955"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((pred - test_data[:, [2]])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c1aee",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aa33380",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "\n",
    "layer_weights = {}\n",
    "layer_biases = {}\n",
    "\n",
    "for i in range(1, num_layers + 1):\n",
    "    layer_weights[i] = model.layers[i].get_weights()[0]\n",
    "    layer_biases[i] = model.layers[i].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c0ec43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3914852 ,  0.16362968,  0.33383545, -0.20063436,  0.7469228 ,\n",
       "         0.76410955,  0.5564589 ,  0.6400655 , -0.68820596, -0.22900069],\n",
       "       [-0.6152893 , -0.69731134,  0.44550797, -0.6975839 , -0.31563833,\n",
       "        -0.42561817,  0.21841656, -0.49402374, -0.07197654, -0.3623813 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73f255b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46205425],\n",
       "       [ 0.13735126],\n",
       "       [ 0.6482053 ],\n",
       "       [-0.64298725],\n",
       "       [-0.21215235],\n",
       "       [-0.25053793],\n",
       "       [-0.19961454],\n",
       "       [-0.46673727],\n",
       "       [ 0.25805578],\n",
       "       [ 0.7932906 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].get_weights()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
